{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "# Predicting Star Ratings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "Our objective is to predict a new venue's popularity from information available when the venue opens.  We will do this by machine learning from a data set of venue popularities provided by Yelp.  The data set contains meta data about the venue (where it is located, the type of food served, etc.).  It also contains a star rating. Note that the venues are not limited to restaurants. This tutorial will walk you through one way to build a machine learning algorithm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "## Metrics and scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "For most questions, you are asked to submit your models `predict` method to the grader. The grader uses a test set to evaluate your model's performance against our reference solution, using the $R^2$ score. It **is** possible to receive a score greater than one, indicating that you've beaten our reference model. We compare our model's score on a test set to your score on the same test set. See how high you can go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "import dill\n",
    "import glob\n",
    "import collections\n",
    "from collections import defaultdict\n",
    "import collections.abc\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "import ujson as json\n",
    "import gzip\n",
    "\n",
    "with gzip.open('yelp_train_academic_dataset_business.json.gz') as f:\n",
    "    data = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_ratings = [row['stars'] for row in data]\n",
    "\n",
    "X = data\n",
    "y = star_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "# Aims\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "## Aim 1: city_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "The venues belong to different cities.  You can imagine that the ratings in some cities are probably higher than others.  We wish to build an estimator to make a prediction based on this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "star_sum = defaultdict(int)\n",
    "count = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "for row, stars in zip(data, star_ratings):\n",
    "    # increment the running sum in star_sum\n",
    "    # increment the running count in count\n",
    "    city = row['city']\n",
    "    star_sum[city] += stars\n",
    "    count[city] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "Now we can calculate the average ratings.  Again, a dictionary makes a good container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(167, 167)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(star_sum), len(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.6702903946388683"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_stars = dict()\n",
    "\n",
    "for city in star_sum:\n",
    "    # calculate average star rating and store in avg_stars\n",
    "    avg_stars[city] = star_sum[city]/count[city]\n",
    "avg_stars['Phoenix']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "There should be 167 different cities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "class CityRegressor(BaseEstimator, RegressorMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.avg_stars = dict()\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Store the average rating per city in self.avg_stars\n",
    "        star_sum = defaultdict(int)\n",
    "        count = defaultdict(int)\n",
    "        for row, stars in zip(X, y):\n",
    "            city = row['city']\n",
    "            star_sum[city] += stars\n",
    "            count[city] += 1\n",
    "        for city in star_sum:\n",
    "            self.avg_stars[city] = star_sum[city]/count[city]\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):  \n",
    "        return [self.avg_stars[row['city']] if row['city'] in self.avg_stars else 0 for row in X  ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": null
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.6702903946388683, 3.75, 3.75, 3.75, 3.75]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_model = CityRegressor()\n",
    "\n",
    "city_model.fit(X, y).predict(X[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": null
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.6702903946388683, 0, 3.6457337883959045]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_model.predict([{'city': 'Phoenix'}, {'city': 'Timbuktu'}, {'city': 'Madison'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('city_model.dill', 'wb') as f:\n",
    "    dill.dump(city_model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "## Aim 2: lat_long_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "You can imagine that a city-based model might not be sufficiently fine-grained. For example, we know that some neighborhoods are trendier than others.  Use the latitude and longitude of a venue as features that help you understand neighborhood dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "class ToDataFrame(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        # This transformer doesn't need to learn anything about the data,\n",
    "        # so it can just return self without any further processing\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Return a pandas data frame from X\n",
    "        return pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "selector = ColumnTransformer([\n",
    "    ('lat', 'passthrough', ['latitude']),\n",
    "    ('lon', 'passthrough', ['longitude'])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": null
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4. , 4.2, 4. , 3.8, 4.2])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "to_data_frame = ToDataFrame()\n",
    "data_transform = to_data_frame.transform(data)\n",
    "data_transform = selector.fit_transform(data_transform)\n",
    "knn = KNeighborsRegressor(n_neighbors=5)\n",
    "knn.fit(data_transform, star_ratings)\n",
    "\n",
    "# Making predictions\n",
    "test_data = data[:5]\n",
    "test_data_transform = to_data_frame.transform(test_data)\n",
    "test_data_transform = selector.transform(test_data_transform)\n",
    "knn.predict(test_data_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": null
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4. , 4.2, 4. , 3.8, 4.2])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_lat_long = Pipeline([\n",
    "    ('to_data_frame', ToDataFrame()),\n",
    "    ('column selection', selector),\n",
    "    ('regressor', knn)\n",
    "])\n",
    "pipe_lat_long.fit(X, y).predict(data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('to_data_frame', ToDataFrame()),\n",
       "  ('column selection',\n",
       "   ColumnTransformer(transformers=[('lat', 'passthrough', ['latitude']),\n",
       "                                   ('lon', 'passthrough', ['longitude'])])),\n",
       "  ('regressor', KNeighborsRegressor())],\n",
       " 'verbose': False,\n",
       " 'to_data_frame': ToDataFrame(),\n",
       " 'column selection': ColumnTransformer(transformers=[('lat', 'passthrough', ['latitude']),\n",
       "                                 ('lon', 'passthrough', ['longitude'])]),\n",
       " 'regressor': KNeighborsRegressor(),\n",
       " 'column selection__n_jobs': None,\n",
       " 'column selection__remainder': 'drop',\n",
       " 'column selection__sparse_threshold': 0.3,\n",
       " 'column selection__transformer_weights': None,\n",
       " 'column selection__transformers': [('lat', 'passthrough', ['latitude']),\n",
       "  ('lon', 'passthrough', ['longitude'])],\n",
       " 'column selection__verbose': False,\n",
       " 'column selection__lat': 'passthrough',\n",
       " 'column selection__lon': 'passthrough',\n",
       " 'regressor__algorithm': 'auto',\n",
       " 'regressor__leaf_size': 30,\n",
       " 'regressor__metric': 'minkowski',\n",
       " 'regressor__metric_params': None,\n",
       " 'regressor__n_jobs': None,\n",
       " 'regressor__n_neighbors': 5,\n",
       " 'regressor__p': 2,\n",
       " 'regressor__weights': 'uniform'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_lat_long.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('to_data_frame', ToDataFrame()),\n",
       "                                       ('column selection',\n",
       "                                        ColumnTransformer(transformers=[('lat',\n",
       "                                                                         'passthrough',\n",
       "                                                                         ['latitude']),\n",
       "                                                                        ('lon',\n",
       "                                                                         'passthrough',\n",
       "                                                                         ['longitude'])])),\n",
       "                                       ('regressor', KNeighborsRegressor())]),\n",
       "             n_jobs=2,\n",
       "             param_grid={'regressor__n_neighbors': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24])},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'regressor__n_neighbors': np.arange(1, 25)}\n",
    "gs_est = GridSearchCV(pipe_lat_long, param_grid, cv=3, n_jobs=2, verbose=1)\n",
    "gs_est.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'regressor__n_neighbors': 24}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_est.best_params_ #the best_params keeps increasing as the range increases, does this sound right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.06528733598592444"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_est.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_long_model = gs_est.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lat_long_model.dill', 'wb') as f:\n",
    "    dill.dump(lat_long_model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "## Aim 3: category_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "While location is important, we could also try seeing how predictive the\n",
    "venue's category is. Build an estimator that considers only the `'categories'` field of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "class DictEncoder(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # X will be a pandas series. Return a pandas series of dictionaries\n",
    "        return X.apply(lambda X: dict.fromkeys(X, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "vec = Pipeline([\n",
    "    ('encoder', DictEncoder()),\n",
    "    ('vectorizer', DictVectorizer())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "Selector_cat = ColumnTransformer([\n",
    "    ('vectorized categories', vec, 'categories')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_model = Pipeline([\n",
    "    ('to_df', ToDataFrame()),\n",
    "    ('feature_selection', Selector_cat),\n",
    "    ('regressor', Ridge())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.33942676, 3.34706925, 3.28311091, 3.22129515, 3.30411137])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_model.fit(X, y).predict(X[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('category_model.dill', 'wb') as f:\n",
    "    dill.dump(category_model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "## Aim 4: attribute_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "There is even more information in the attributes for each venue.  Let's build an estimator based on these.\n",
    "\n",
    "Venues attributes may be nested:\n",
    "```python\n",
    "{\n",
    "  'Attire': 'casual',\n",
    "  'Accepts Credit Cards': True,\n",
    "  'Ambiance': {'casual': False, 'classy': False}\n",
    "}\n",
    "```\n",
    "We wish to encode them in the same manner as our categories data using the `DictVectorizer`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(d, parent_key='', sep='_'):\n",
    "    items = []\n",
    "    for k, v in d.items():\n",
    "        new_key = parent_key + sep + k if parent_key else k\n",
    "        if isinstance(v, collections.abc.MutableMapping):\n",
    "            items.extend(flatten(v, new_key, sep=sep).items())\n",
    "        elif isinstance(v, bool):\n",
    "            items.append((new_key, int(v)))\n",
    "        else:\n",
    "            items.append((new_key, 1))\n",
    "    return dict(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DictFlat(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # X will be a pandas series. Return a pandas series of dictionaries\n",
    "        return X.apply(lambda X: flatten(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<37938x78 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 531447 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = Pipeline([\n",
    "    ('encoder', DictFlat()),\n",
    "    ('vectorizer', DictVectorizer())\n",
    "])\n",
    "\n",
    "Selector_att = ColumnTransformer([\n",
    "    ('vectorized attributes', vec, 'attributes')\n",
    "])\n",
    "\n",
    "pipe_trans = Pipeline([\n",
    "    ('to_df', ToDataFrame()),\n",
    "    ('feature_selection', Selector_att),\n",
    "])\n",
    "\n",
    "X_trans = pipe_trans.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "{'alpha': 12.742749857031322}\n",
      "0.0033902783589166616\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'alpha': np.logspace(-3,3,20)}\n",
    "gs_ridge = GridSearchCV(Ridge(), param_grid, cv=3, n_jobs=2, verbose=1)\n",
    "gs_ridge.fit(X_trans, y)\n",
    "print(gs_ridge.best_params_)\n",
    "print(gs_ridge.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.052435  , 3.42818792, 3.58667198, 3.27442234, 3.26061997])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_ridge.best_estimator_.predict(X_trans[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleRegressor(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, lin, nonlin):\n",
    "        self.lin = lin\n",
    "        self.nonlin = nonlin\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.lin.fit(X, y)\n",
    "        y_res = y - self.lin.predict(X)\n",
    "        self.nonlin.fit(X, y_res)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):        \n",
    "        return (self.nonlin.predict(X)+self.lin.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = EnsembleRegressor(gs_ridge.best_estimator_, rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EnsembleRegressor(lin=Ridge(alpha=12.742749857031322),\n",
       "                  nonlin=RandomForestRegressor(random_state=42))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(X_trans, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lin__alpha': 12.742749857031322,\n",
       " 'lin__copy_X': True,\n",
       " 'lin__fit_intercept': True,\n",
       " 'lin__max_iter': None,\n",
       " 'lin__normalize': False,\n",
       " 'lin__random_state': None,\n",
       " 'lin__solver': 'auto',\n",
       " 'lin__tol': 0.001,\n",
       " 'lin': Ridge(alpha=12.742749857031322),\n",
       " 'nonlin__bootstrap': True,\n",
       " 'nonlin__ccp_alpha': 0.0,\n",
       " 'nonlin__criterion': 'mse',\n",
       " 'nonlin__max_depth': None,\n",
       " 'nonlin__max_features': 'auto',\n",
       " 'nonlin__max_leaf_nodes': None,\n",
       " 'nonlin__max_samples': None,\n",
       " 'nonlin__min_impurity_decrease': 0.0,\n",
       " 'nonlin__min_impurity_split': None,\n",
       " 'nonlin__min_samples_leaf': 1,\n",
       " 'nonlin__min_samples_split': 2,\n",
       " 'nonlin__min_weight_fraction_leaf': 0.0,\n",
       " 'nonlin__n_estimators': 100,\n",
       " 'nonlin__n_jobs': None,\n",
       " 'nonlin__oob_score': False,\n",
       " 'nonlin__random_state': 42,\n",
       " 'nonlin__verbose': 0,\n",
       " 'nonlin__warm_start': False,\n",
       " 'nonlin': RandomForestRegressor(random_state=42)}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 45 candidates, totalling 135 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=EnsembleRegressor(lin=Ridge(alpha=12.742749857031322),\n",
       "                                         nonlin=RandomForestRegressor(random_state=42)),\n",
       "             n_jobs=2,\n",
       "             param_grid={'nonlin__max_depth': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]),\n",
       "                         'nonlin__min_samples_leaf': array([1, 2, 3])},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_reg = {'nonlin__max_depth': np.arange(1,16),\n",
    "             'nonlin__min_samples_leaf': np.arange(1,4)}\n",
    "\n",
    "gs_reg = GridSearchCV(regressor, params_reg, cv=3, n_jobs=2, verbose=1)\n",
    "gs_reg.fit(X_trans, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nonlin__max_depth': 15, 'nonlin__min_samples_leaf': 3}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_reg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.90168891, 3.4389031 , 3.55879558, 3.80417926, 3.40617893])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_reg.best_estimator_.predict(X_trans[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute_model = Pipeline([\n",
    "    ('to_df', ToDataFrame()),\n",
    "    ('feature_selection', Selector_att),\n",
    "    ('regressor', gs_reg.best_estimator_)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('to_df', ToDataFrame()),\n",
       "                ('feature_selection',\n",
       "                 ColumnTransformer(transformers=[('vectorized attributes',\n",
       "                                                  Pipeline(steps=[('encoder',\n",
       "                                                                   DictFlat()),\n",
       "                                                                  ('vectorizer',\n",
       "                                                                   DictVectorizer())]),\n",
       "                                                  'attributes')])),\n",
       "                ('regressor',\n",
       "                 EnsembleRegressor(lin=Ridge(alpha=12.742749857031322),\n",
       "                                   nonlin=RandomForestRegressor(max_depth=15,\n",
       "                                                                min_samples_leaf=3,\n",
       "                                                                random_state=42)))])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attribute_model.fit(X, y).predict(X[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('attribute_model.dill', 'wb') as f:\n",
    "    dill.dump(attribute_model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "## Aim 5: full_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "So far we have only built models based on individual features.  Now we will build an ensemble regressor that averages together the estimates of the four previous regressors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "class ModelTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, model):\n",
    "        # What needs to be done here?\n",
    "        self.model = model\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        # Fit the stored predictor.\n",
    "        # Question: what should be returned?\n",
    "        self.model.fit(X, y)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Use predict on the stored predictor as a \"transformation\".\n",
    "        # Be sure to return a 2-D array.\n",
    "        return np.array(self.model.predict(X)).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "Create an instance of `ModelTransformer` for each of the previous four models. Combine these together in a single feature matrix with a\n",
    "[`FeatureUnion`](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.FeatureUnion.html#sklearn.pipeline.FeatureUnion)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('city_model.dill', 'rb') as f:\n",
    "    city_model = dill.load(f)\n",
    "city_trans = ModelTransformer(city_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lat_long_model.dill', 'rb') as f:\n",
    "    lat_long_model = dill.load(f)\n",
    "lat_long_trans = ModelTransformer(lat_long_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('category_model.dill', 'rb') as f:\n",
    "    category_model = dill.load(f)\n",
    "category_trans = ModelTransformer(category_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('attribute_model.dill', 'rb') as f:\n",
    "    attribute_model = dill.load(f)  \n",
    "attribute_trans = ModelTransformer(attribute_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "union = FeatureUnion([\n",
    "        ('city', city_trans),\n",
    "        ('lat_long', lat_long_trans),\n",
    "        ('categories', category_trans),\n",
    "        ('attributes', attribute_trans)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model = Pipeline([\n",
    "    ('predictors', union),\n",
    "    ('regressor', Ridge())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.77054705, 3.36661673, 3.41654682, 3.43346548, 3.39675801])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_model.fit(X, y).predict(X[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "nbclean": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
